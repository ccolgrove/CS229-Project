<?xml version="1.0"?><api><query><redirects><r from="Playback speed" to="Audio timescale-pitch modification" /></redirects><pages><page pageid="46943" ns="0" title="Audio timescale-pitch modification"><revisions><rev xml:space="preserve">{{About|time stretching in audio|other uses|Time stretching (disambiguation)}}
'''Time stretching''' is the process of changing the speed or duration of an [[audio signal processing|audio signal]] without affecting its [[pitch (music)|pitch]].
'''Pitch scaling''' or '''pitch shifting''' is the opposite: the process of changing the pitch without affecting the speed. There are also more advanced methods used to change speed, pitch, or both at once, as a function of time.

These processes are used, for instance, to match the pitches and tempos of two pre-recorded clips for mixing when the clips cannot be reperformed or resampled. (A drum track containing no pitched instruments could be moderately resampled for tempo without adverse effects, but a pitched track could not). They are also used to create effects such as increasing the range of an instrument (like pitch shifting a guitar down an octave).

==Resampling==
The simplest way to change the duration or pitch of a [[digital signal|digital]] audio clip is to [[resampling|resample]] it. This is a mathematical operation that effectively rebuilds a continuous waveform from its samples and then samples that waveform again at a different rate. When the new samples are played at the original sampling frequency, the audio clip sounds faster or slower. Unfortunately, the frequencies in the sample are always scaled at the same rate as the speed, transposing its perceived pitch up or down in the process. In other words, slowing down the recording lowers the pitch, speeding it up raises the pitch, and the two effects cannot be separated.  This is analogous to speeding up or slowing down an [[analog signal|analog]] recording, like a [[phonograph record]] or [[Sound recording#Magnetic Recording|tape]], creating [[The Chipmunks#Recording technique|the chipmunk effect]].

== Phase vocoder ==
{{Main|Phase vocoder}}
One way of stretching the length of a signal without affecting the pitch is to build a [[phase vocoder]] after Flanagan, Golden, and Portnoff.

Basic steps:
#compute the instantaneous frequency/amplitude relationship of the signal using the [[Short-time Fourier transform|STFT]], which is the [[discrete Fourier transform]] of a short, overlapping and smoothly windowed block of samples;
#apply some processing to the Fourier transform magnitudes and phases (like resampling the FFT blocks); and
#perform an inverse STFT by taking the inverse Fourier transform on each chunk and adding the resulting waveform chunks.

The phase vocoder handles [[sinusoid]] components well, but early implementations introduced considerable smearing on [[transient (acoustics)|transient]] (&quot;beat&quot;) waveforms at all non-integer compression/expansion rates, which renders the results phasey and diffuse. Recent improvements allow better quality results at all compression/expansion ratios but a residual smearing effect still remains.

The phase vocoder technique can also be used to perform pitch shifting, chorusing, timbre manipulation, harmonizing, and other unusual modifications, all of which can be changed as a function of time.

== Time domain ==
=== SOLA ===

[[Rabiner]] and Schafer in 1978 put forth an alternate solution that works in the [[time domain]]: attempt to find the [[periodic signal|period]] (or equivalently the [[fundamental frequency]]) of a given section of the wave using some [[pitch detection algorithm]] (commonly the peak of the signal's [[autocorrelation]], or sometimes [[cepstrum|cepstral]] processing), and [[fade (audio engineering)|crossfade]] one period into another.

This is called time domain harmonic scaling&lt;ref&gt;{{cite journal
 | author = David Malah
 | year = 1979
 | month = April
 | title = Time-domain algorithms for harmonic bandwidth reduction and time scaling of speech signals
 | journal = IEEE Transactions on Acoustics, Speech, and Signal Processing
 | volume = ASSP-27
 | issue = 2
 | pages = 121â133
}}&lt;/ref&gt; or the synchronized overlap-add method (SOLA) and performs somewhat faster than the phase vocoder on slower machines but fails when the autocorrelation mis-estimates the period of a signal with complicated harmonics (such as [[orchestra]]l pieces).

[[Adobe Audition]] (formerly Cool Edit Pro) seems to solve this by looking for the period closest to a center period that the user specifies, which should be an integer multiple of the tempo, and between 30 [[hertz|Hz]] and the lowest bass frequency.

This is much more limited in scope than the phase vocoder based processing, but can be made much less processor intensive, for real-time applications. It provides the most coherent results for single-pitched sounds like voice or musically monophonic instrument recordings.

High-end commercial audio processing packages either combine the two techniques (for example by separating the signal into sinusoid and transient waveforms), or use other techniques based on the [[wavelet]] transform, or artificial neural network processing, producing the highest-quality time stretching.

=== Untangling phase and time ===

[[File:MonophonicSoundCylinderModel.svg|thumb|200px|right|Modelling a monophonic sound as observation along a helix of a function with a cylinder domain]]
Another way to shift pitch and stretch time is to separate phase and time in a monophonic sound such as the ones of [[melody instrument]]s.
By altering only the time control, you can stretch, shrink or reverse time, or generate [[Sampling (music)#Musical instruments|loop]]s as needed in [[Sample-based synthesis|sampling synthesizer]]s.
Time shrinkage can also be used for [[data compression|compression]] purposes.
By altering only the phase control, you can shift the pitch or apply [[FM synthesis]] distortions to an existing sound.
This can be used to play instruments alternatively to [[wavetable synthesis]].

For controlling phase and time independently we would need to know the displacement of the sound for every pair of phase and time position.
This corresponds to a cylinder as shown in the figure.
However, a sound signal is a one-dimensional signal.
You can consider this sound signal as observation of the full function on the cylinder. This is drawn as black line in the figure.
The full function on the cylinder can be approximated by interpolating between points on the helix with (approximately) the same phase.
From this function a different sound signal can be derived.
E.g. in the figure the grey line shows the path of a sound that has the same time progression but a frequency lower than the original one,
or a sound that has the same frequency and a faster time progression, or something between.
In the end the whole process can be implemented for discrete sound signals as interpolation between values with similar phase and similar time.
&lt;ref&gt;{{cite journal
 | last = Thielemann | first = Henning
 | year = 2010
 | month = December
 | title = Untangling phase and time in monophonic sounds
 | journal = Journal of Signal and Information Processing
 | volume = 1 | issue = 1 | pages = 1â17
 | arxiv = 0911.5171
 | doi = 10.4236/jsip.2010.11001
}}&lt;/ref&gt;

The described technique is used in the monophonic version of the software [[Melodyne]]&lt;ref&gt;{{Citation
|url=http://www.youtube.com/watch?v=u573PyXo-pY
|title=Melodyne inventor Peter NeubÃ¤cker (film portrait) (starting from 26:00)
|work=YouTube
|publisher=[[Celemony]]
|accessdate=2011-09-11
}}&lt;/ref&gt;

== Sinusoidal/Spectral Modeling ==

Another alternative method for time stretching relies on a [[Spectral modelling synthesis|spectral model]] of the signal.  In this method, peaks are identified in frames using the [[Short-time Fourier transform|STFT]] of the signal, and sinusoidal &quot;tracks&quot; are created by connecting peaks in adjacent frames.  The tracks are then re-synthesized at a new time scale.  This method can yield good results on both polyphonic and percussive material, especially when the signal is separated into sub-bands.  However, this method is more computationally demanding than other methods.

== Speed hearing &amp; Speed Talking==

For the specific case of speech, time stretching can be performed using [[PSOLA]].

Time stretching can be used with [[audio book]]s and recorded lectures.
Slowing down may improve comprehension of foreign languages [http://www.enounce.com/whatistsm.shtml].

While one might expect speeding up to reduce comprehension,
Herb Friedman says that &quot;Experiments have shown that the brain works most efficiently if the information rate through the ears--via speech--is the &quot;average&quot; reading rate, which is about 200-300 wpm (words per minute), yet the average rate of speech is in the neighborhood of 100-150 wpm.&quot;
[http://www.atarimagazines.com/creative/v9n7/122_Variable_speech.php ]

Speeding up audio is seen as the equivalent of &quot;[[speed reading]]&quot;
[http://www.nevsblog.com/2006/06/23/listen-to-podcasts-in-half-the-time/ ]
[http://cid.lib.byu.edu/?p=128 ].

Time stretching is often used to adjust [[Radio commercial]]s
[http://web.archive.org/web/20080527184101/http://www.tvtechnology.com/features/audio_notes/f_audionotes.shtml] and the audio of [[Television advertisement]]s [http://www.atarimagazines.com/creative/v9n7/122_Variable_speech.php] to fit exactly into the 30 or 60 seconds available.

== Pitch scaling ==

These techniques can also be used to [[transposition (music)|transpose]] an audio sample while holding speed or duration constant.  This may be accomplished by time stretching and then resampling back to the original length.  Alternatively, the frequency of the sinusoids in a [[sinusoidal model]] may be altered directly, and the signal reconstructed at the appropriate time scale.

Transposing can be called '''[[frequency]] scaling''' or '''[[pitch shift]]ing''', depending on perspective.

For example, one could move the pitch of every note up by a perfect fifth, keeping the tempo the same.
One can view this transposition as &quot;pitch shifting&quot;, &quot;shifting&quot; each note up 7 keys on a piano keyboard, or adding a fixed amount on the [[Mel scale]], or adding a fixed amount in linear [[pitch space]].
One can view the same transposition as &quot;frequency scaling&quot;, &quot;scaling&quot; (multiplying) the frequency of every note by 3/2.

Musical transposition preserves the ratios of the [[harmonic]] frequencies that determine the sound's [[timbre]], unlike the ''frequency shift'' performed by [[amplitude modulation]], which adds a fixed frequency offset to the frequency of every note. (In theory one could perform a literal ''pitch scaling'' in which the musical pitch space location is scaled [a higher note would be shifted at a greater interval in linear pitch space than a lower note], but that is highly unusual, and not musical{{Citation needed|date={{currentmonthname}} {{currentyear}}}}).

Time domain processing works much better here, as smearing is less noticeable, but scaling vocal samples distorts the [[formant]]s into a sort of [[Alvin and the Chipmunks]]-like effect, which may be desirable or undesirable.
A process that preserves the formants and character of a voice involves analyzing the signal with a [[vocoder|channel vocoder]] or [[Linear predictive coding|LPC]] vocoder plus any of several [[pitch detection algorithm]]s and then resynthesizing it at a different fundamental frequency.

A detailed description of older analog recording techniques for pitch shifting can be found within the [[Alvin and the Chipmunks]] entry.

==See also==
*[[Audio signal processing]]
*[[Pitch control]]
*[[Sound effect]]s
*[[Time-compressed speech]]
*[[PSOLA]]

== References ==
&lt;references /&gt;

== External links ==
*[http://www.dspdimension.com/admin/time-pitch-overview/ Time Stretching and Pitch Shifting Overview] A comprehensive overview of current time and pitch modification techniques by Stephan Bernsee
*[http://www.dspdimension.com/admin/pitch-shifting-using-the-ft/ Stephan Bernsee's smbPitchShift C source code] C source code for doing frequency domain pitch manipulation
*[https://github.com/janesconference/KievII/blob/master/dsp/pitchshift.js pitchsift.js from KievII] A Javascript pitchshifter based on smbPitchShift code, from the open source [https://github.com/janesconference/KievII KievII library]
*[http://www.panix.com/~jens/pvoc-dolson.par The Phase Vocoder: A Tutorial] - A good description of the phase vocoder
*[http://www.ee.columbia.edu/~dpwe/papers/LaroD99-pvoc.pdf New Phase-Vocoder Techniques for Pitch-Shifting, Harmonizing and Other Exotic Effects]
*[http://www.ircam.fr/equipes/analyse-synthese/roebel/paper/dafx2003.pdf A new Approach to Transient Processing in the Phase Vocoder]
*[http://keizai.yokkaichi-u.ac.jp/~ikeda/research/picola.html PICOLA and TDHS]
*[http://www.guitarpitchshifter.com How to build a pitch shifter] Theory, equations, figures and performances of a real-time guitar pitch shifter running on a DSP chip
*[http://www.zplane.de/index.php?page=description-elastique Elastique from Zplane] Code used in most of the DJ software

[[Category:Audio engineering]]
[[Category:Digital signal processing]]
[[Category:Sound effects]]

[[de:Time-Stretching]]
[[fr:Time stretching]]
[[it:Timestretching]]
[[sv:Timestretch]]</rev></revisions></page></pages></query></api>
